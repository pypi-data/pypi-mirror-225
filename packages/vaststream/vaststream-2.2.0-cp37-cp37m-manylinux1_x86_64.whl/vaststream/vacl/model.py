# Copyright (C) 2022-2023 VASTAI Technologies Co., Ltd. All Rights Reserved.
# coding: utf-8
__all__ = [
    "createModel", "destroyModel", "createDynamicModel",
    "setDynamicModelInputShape", "setModelBatchSize", "getModelBatchSize",
    "getModelMaxBatchSize", "getDynamicModelMaxBatchSize",
    "getModelOutputSizeByIndex", "getModelOutputDataTypeByIndex",
    "getModelInputCount", "getModelOutputCount", "getModelInputShapeByIndex",
    "getModelOutputShapeByIndex","getModelAlignOutputSizeByIndex","getModelAlignOutput", 
    "getModelOutput", "getModelAddress", "getModelScale", "getModelTensorType",
    "Model", "ModelDataset"
]

import os
from _vaststream_pybind11 import vacl as _vacl, vacm as _vacm
import numpy as np
from typing import List, Union
from vaststream.vacm import *
from .common import *
from .utils import *


class Model(PointerContainer):
    """Model tool class.

    This class support static model and dynamic model, contains all operations on the model.

    Args:
        modLib (str): Model library file (.so) generated by compiler.
        modGraph (str): The file with the model graph description.
        modParam (str): The file with the model parameter.
        modSuitesConfig (str): The JSON file with the description of a group of 3-model files for a dynamic model. 
            All these files must be in the same location.
        hwConfig (str): The config file with the hardware configuration(default None).

    Examples:
        >>> # create a dynamic model
        >>> shape = vacm.Shape()
        >>> shape.ndims = 4
        >>> shape.shapes = [1, 3, 320, 240]
        >>> model = vacl.Model(modSuitesConfig=..., hwConfig=...)
        >>> model.setDynamicInputShape(shape)
        >>> model.setBatchSize(1)
        >>> print("Model batchsize: ", model.batchsize)
        >>> print("Model max batchsize: ", model.getDynamicMaxBatchSize(shape))
        >>> # create a static model
        >>> model = vacl.Model(modLib=..., modGraph=..., modParam=...)
        >>> model.setBatchSize(1)
        >>> print("Model batchsize: ", model.batchsize)
        >>> print("Model max batchsize: ", model.getMaxBatchSize())
    """

    def __init__(self,
                 modLib: str = None,
                 modGraph: str = None,
                 modParam: str = None,
                 hwConfig: str = "",
                 modSuitesConfig: str = None):
        self.modLib = modLib
        self.modGraph = modGraph
        self.modParam = modParam
        self.hwConfig = hwConfig
        self.modSuitesConfig = modSuitesConfig
        self.dynamic = True if self.modSuitesConfig is not None else False
        # 非动态模型校验
        if not self.dynamic:
            assert all(arg is not None for arg in [modLib, modGraph, modParam])
        if self.hwConfig:
            assert os.path.exists(
                self.hwConfig), f"Can not find file {self.hwConfig}."
        self._ptr = None
        self.create()

    def __del__(self):
        self.destroy()

    def __eq__(self, other) -> bool:
        if isinstance(other, Model):
            return self.id == other.id
        return False

    def _check_destroy(self):
        assert self._ptr is not None, "model has been destroyed."

    @property
    def batchsize(self) -> int:
        """The batchsize of the model."""
        return self.getBatchSize()

    @property
    def inputCount(self) -> int:
        """The input count of the model."""
        return self.getInputCount()

    @property
    def outputCount(self) -> int:
        """The output count of the model."""
        return self.getOutputCount()

    def create(self) -> None:
        """Create the model."""
        if self._ptr is None:
            if self.dynamic:
                self._ptr = _vacl.createDynamicModel(self.modSuitesConfig,
                                                     self.hwConfig)
            else:
                self._ptr = _vacl.createModel(self.modLib, self.modGraph,
                                              self.modParam, self.hwConfig)

    @err_check
    def destroy(self) -> int:
        """Destroy the model."""
        ret = _vacl.vaclER_SUCCESS
        if self._ptr is not None:
            ret = _vacl.destroyModel(self.ptr)
            self._ptr = None
        return ret

    @err_check
    def setDynamicInputShape(self, shapes: Union[Shape, List[Shape]]):
        """Set the input shape for a dynamic model.
        
        Args:
            shape (Shape): Input shape list for the dynamic model.
        
        Returns:
            int: The return code. 0 for success, False otherwise.
        """
        self._check_destroy()
        assert self.dynamic, "Only support dynamic model."
        if isinstance(shapes, Shape): shapes = [shapes]
        return _vacl.setDynamicModelInputShape(self.ptr, shapes)

    @err_check
    def setBatchSize(self, batchSize: int) -> int:
        """Set the batch size for a model.
    
        Args:
            batchSize (int): The batchsize to be setted.
        
        Hint:
            If input batch size is more than optimal batch size, it will be set as optimal value.
        
        Returns:
            int: The return code. 0 for success, False otherwise.
        """
        self._check_destroy()
        return _vacl.setModelBatchSize(self.ptr, batchSize)

    def getBatchSize(self) -> int:
        """Get the batch size for a model.
        
        Returns:
            int: The model batch size.
        """
        self._check_destroy()
        return _vacl.getModelBatchSize(self.ptr)

    def getMaxBatchSize(self) -> int:
        """Get the maximum batch size for a model.
        
        Returns:
            int: The model max batch size.        
        """
        self._check_destroy()
        assert not self.dynamic, "Only support static model, please use getDynamicMaxBatchSize."
        return _vacl.getModelMaxBatchSize(self.ptr)

    def getDynamicMaxBatchSize(self, shapes: Union[Shape, List[Shape]]) -> int:
        """Get the maximum batch size for a dynamic model.
    
        Args:
            shapes (Union[Shape, List[Shape]]): Input shape list for the model.
            count (int): Count of input shape array.
        
        Returns:
            int: The dynamic model max batch size. 
        """
        self._check_destroy()
        assert self.dynamic, "Only support dynamic model."
        if isinstance(shapes, Shape): shapes = [shapes]
        return _vacl.getDynamicModelMaxBatchSize(self.ptr, shapes)

    def getOutputSizeByIndex(self, index: int) -> int:
        """Get the output data size by index for a model.

        Args:
            index (int): Index of output.
        
        Returns:
            int: The size of the model output. 
        """
        self._check_destroy()
        outputCount = self.getOutputCount()
        if index < 0 or index >= outputCount:
            raise RuntimeError(
                f"index out of range, model support 0 <= index < {outputCount}."
            )
        return _vacl.getModelOutputSizeByIndex(self.ptr, index)

    def getOutputDataTypeByIndex(self, index: int) -> D_TYPE:
        """Get the output data type by index for a model.
    
        Args:
            index (int): Index of output.
        
        Returns:
            D_TYPE: The data type of the model output.
        """
        self._check_destroy()
        outputCount = self.getOutputCount()
        if index < 0 or index >= outputCount:
            raise RuntimeError(
                f"index out of range, model support 0 <= index < {outputCount}."
            )
        return _vacl.getModelOutputDataTypeByIndex(self.ptr, index)

    def getInputCount(self) -> int:
        """Get the input count for a model.
        
        Returns:
            int: The input count of the model. 
        """
        self._check_destroy()
        return _vacl.getModelInputCount(self.ptr)

    def getOutputCount(self) -> int:
        """Get the output count for a model.
        
        Returns:
            int: The output count of the model. 
        """
        self._check_destroy()
        return _vacl.getModelOutputCount(self.ptr)

    def getInputShapeByIndex(self, index: int) -> Shape:
        """Get the input shape by index for a model.
        
        Args:
            index (int): Index of input.
        
        Returns:
            Shape: The intput shpe of the model.
        """
        self._check_destroy()
        inputCount = self.getInputCount()
        if index < 0 or index >= inputCount:
            raise RuntimeError(
                f"index out of range, model support 0 <= index < {inputCount}."
            )
        shape = _vacm.shape()
        ret = _vacl.getModelInputShapeByIndex(self.ptr, index, shape)
        if ret != _vacl.vaclER_SUCCESS:
            raise RuntimeError(
                f"get model input shape by index error, ret: {ret}.")
        return shape

    def getOutputShapeByIndex(self, index: int) -> Shape:
        """Get the output shape by index for a model.
       
        Args:
            index (int): Index of output.
        
        Returns:
            Shape: The output shpe of the model.
        """
        self._check_destroy()
        outputCount = self.getOutputCount()
        if index < 0 or index >= outputCount:
            raise RuntimeError(
                f"index out of range, model support 0 <= index < {outputCount}."
            )
        shape = _vacm.shape()
        ret = _vacl.getModelOutputShapeByIndex(self.ptr, index, shape)
        if ret != _vacl.vaclER_SUCCESS:
            raise RuntimeError(
                f"get model output shape by index error, ret: {ret}.")
        return shape

    def getAddress(self) -> int:
        """Get the address count for a model.
        
        Returns:
            int: The output count of the model. 
        """
        self._check_destroy()
        return _vacl.getModelAddress(self.ptr)
    
    def getScale(self, index: int) -> float:
        """Get the scale for a model.
        
        Returns:
            int: The output count of the model. 
        """
        self._check_destroy()
        return _vacl.getModelScale(self.ptr, index)
    
    def getTensorType(self, index: int) -> int:
        """Get the scale for a model.
        
        Returns:
            int: The output count of the model. 
        """
        self._check_destroy()
        return _vacl.getModelTensorType(self.ptr, index)
    
    def getAlignOutputSizeByIndex(self, index: int) -> int:
        """Get the Align output data size by index for a model.

        Args:
            index (int): Index of output.
        
        Returns:
            int: The size of the model output. 
        """
        self._check_destroy()
        outputCount = self.getOutputCount()
        if index < 0 or index >= outputCount:
            raise RuntimeError(
                f"index out of range, model support 0 <= index < {outputCount}."
            )
        return _vacl.getModelAlignOutputSizeByIndex(self.ptr, index)
   
    def getAlignOutput(self, index: int, deviceData: DataHandle, hostData: DataHandle) -> int:
        """Get the Align output by index for a model.

        Args:
            index (int): Index of output.
            deviceData (DataHandle):  output address on device
            hostData (DataHandle):  a pointer to host memory. 

        Returns:
            int: Error code of the api return. 0 means success, otherwise failure.
        """
        self._check_destroy()
        outputCount = self.getOutputCount()
        if index < 0 or index >= outputCount:
            raise RuntimeError(
                "index out of range, model support 0 <= index < {outputCount}."
            )
        return _vacl.getModelAlignOutput(self.ptr, index, deviceData.ptr, hostData.ptr)
    
    def getOutput(self, index: int, deviceData: DataHandle, hostData: DataHandle) -> int:
        """Get the real output by index for a model.

        Args:
            index (int): Index of output.
            deviceData (DataHandle):  output address on device
            hostData (DataHandle):  a pointer to host memory. 

        Returns:
            int: Error code of the api return. 0 means success, otherwise failure. 
        """
        self._check_destroy()
        outputCount = self.getOutputCount()
        if index < 0 or index >= outputCount:
            raise RuntimeError(
                "index out of range, model support 0 <= index < {outputCount}."
            )
        return _vacl.getModelOutput(self.ptr, index, deviceData.ptr, hostData.ptr)
    
def createModel(modLib: str, modGraph: str, modParam: str,
                hwConfig: str) -> Model:
    """Create a model from files.
    
    Args:
        modLib (str): Model library file (.so) generated by compiler.
        modGraph (str): The file with the model graph description.
        modParam (str): The file with the model parameter.
        hwConfig (str): The config file with the hardware configuration(default None).
    
    Returns:
        Model: The model instance.
    """
    return Model(modLib=modLib,
                 modGraph=modGraph,
                 modParam=modParam,
                 hwConfig=hwConfig)


def destroyModel(model: Model) -> int:
    """Destroy the model.
    
    Args:
        model (Model): The model instance.
    
    Returns:
        int: The return code. 0 for success, False otherwise.
    """
    return model.destroy()


def createDynamicModel(modSuitesConfig: str, hwConfig: str) -> Model:
    """Create a dynamic model from files.
    
    Args:
        modSuitesConfig (str): The JSON file with the description of a group of 3-model files for a dynamic model. 
            All these files must be in the same location.
        hwConfig (str): The JSON file with the hardware configuration(default None).
    
    Returns:
        Model:  The dynamic model instance.
    """
    return Model(modSuitesConfig=modSuitesConfig, hwConfig=hwConfig)


def setDynamicModelInputShape(model: Model, shapes: Union[Shape,
                                                          List[Shape]]) -> int:
    """Set the input shape for a dynamic model.
    
    Args:
        model (Model): A dynamic model instance.
        shape (Union[Shape, List[Shape]]): Input shape list for the dynamic model.
    
    Returns:
        int: The return code. 0 for success, False otherwise.
    """
    return model.setDynamicInputShape(shapes)


def setModelBatchSize(model: Model, batchSize: int) -> int:
    """Set the batch size for a model.
    
    Args:
        model (Model): A model instance.
        batchSize (int): The batchsize to be setted.
    
    Hint:
        If input batch size is more than optimal batch size, it will be set as optimal value.
    
    Returns:
        int: The return code. 0 for success, False otherwise.
    """
    return model.setBatchSize(batchSize)


def getModelBatchSize(model: Model) -> int:
    """Get the batch size for a model.
    
    Args:
        model (Model): A model instance.
    
    Returns:
        int: The batch size of the model.
    """
    return model.batchsize


def getModelMaxBatchSize(model: Model) -> int:
    """Get the maximum batch size for a model.
    
    Args:
        model (Model): A model instance.
    
    Returns:
        int: The maximum batch size of the model.
    """
    return model.getMaxBatchSize()


def getDynamicModelMaxBatchSize(model: Model,
                                shapes: Union[Shape, List[Shape]]) -> int:
    """Get the maximum batch size for a dynamic model.
    
    Args:
        model (Model): A model instance.
        shapes (Union[Shape, List[Shape]]): Input shape list for the model.
    
    Returns:
        int: The maximum batch size of the dynamic model.
    """
    return model.getDynamicMaxBatchSize(shapes)


def getModelOutputSizeByIndex(model: Model, index: int) -> int:
    """Get the output data size by index for a model.

    Args:
        model (Model): A model instance.
        index (int): Index of output.
    
    Returns:
        int: The size of the model output.
    """
    return model.getOutputSizeByIndex(index)


def getModelOutputDataTypeByIndex(model: Model, index: int) -> D_TYPE:
    """Get the output data type by index for a model.
    
    Args:
        model (Model):  A model instance.
        index (int): Index of output.
    
    Returns:
        D_TYPE: The data type of the model output.
    """
    return model.getOutputDataTypeByIndex(index)


def getModelInputCount(model: Model) -> int:
    """Get the input count for a model.
    
    Args:
        model (Model): A model instance.
    
    Returns:
        int: The input count of the model.
    """
    return model.getInputCount()


def getModelOutputCount(model: Model) -> int:
    """Get the output count for a model.
    
    Args:
        model (Model): A model instance.
    
    Returns:
        int: The output count of the model.
    """
    return model.getOutputCount()


def getModelInputShapeByIndex(model: Model, index: int) -> Shape:
    """Get the input shape by index for a model.
    
    Args:
        model (Model): A model instance.
        index (int): Index of input.
    
    Returns:
        Shape: The intput shpe of the model.
    """
    return model.getInputShapeByIndex(index)


def getModelOutputShapeByIndex(model: Model, index: int) -> Shape:
    """Get the output shape by index for a model.
    
    Args:
        model (Model):  A model instance.
        index (int): Index of output.
    
    Returns:
        Shape: The output shape of the model.
    """
    return model.getOutputShapeByIndex(index)

def getModelAddress(model: Model) -> int:
    """Get the address for a model.
    
    Args:
        model (Model):  A model instance.
    
    Returns:
        Shape: The address of the model.
    """
    return model.getAddress()

def getModelScale(model: Model, index: int) -> float:
    """Get the output shape by index for a model.
    
    Args:
        model (Model):  A model instance.
        index (int): Index of output.
    
    Returns:
        Shape: The output shape of the model.
    """
    return model.getScale(index)

def getModelTensorType(model: Model, index: int) -> int:
    """Get the output shape by index for a model.
    
    Args:
        model (Model):  A model instance.
        index (int): Index of output.
    
    Returns:
        Shape: The output shape of the model.
    """
    return model.getTensorType(index)

def getModelAlignOutputSizeByIndex(model: Model, index: int) -> int:
    """Get the output shape by index for a model.
    
    Args:
        model (Model):  A model instance.
        index (int): Index of output.
    
    Returns:
        int: The size in byte(s) of the model output.
    """
    return model.getAlignOutputSizeByIndex(index)

def getModelAlignOutput(model: Model, index: int, deviceData: DataHandle, hostData: DataHandle) -> int:
    """Get the Align output by index for a model.

    Args:
        index (int): Index of output.
        deviceData (DataHandle):  output address on device
        hostData (DataHandle):  a pointer to host memory. 

    Returns:
        int: Error code of the api return. 0 means success, otherwise failure.
    """
    return model.getAlignOutput(index, deviceData, hostData)

def getModelOutput(model: Model, index: int, deviceData: DataHandle, hostData: DataHandle) -> int:
    """Get the real output by index for a model.

    Args:
        index (int): Index of output.
        deviceData (DataHandle):  output address on device
        hostData (DataHandle):  a pointer to host memory. 

    Returns:
        int: Error code of the api return. 0 means success, otherwise failure.
    """
    return model.getOutput(index, deviceData, hostData)

class ModelDataset(Dataset):
    """ModelDataset tool class.

    It's complex to manage the model inputs and parse the model outputs, especially
    in the heterogeneous system.This class greatly simplifies the process, it accept 
    a numpy data to be the model input dataset and parse the model output dataset to 
    be a list of results, you no longer pay attention to hardware implementation details.

    Hint:
        The data will transfer to device, please call destroy to release resources.

    Args:
        data (Union[np.ndarray, List[np.ndarray], Dataset]): The data in the ModelDataset.
        type (str): The type of the model dataset, it should be input or output.

    Examples:
        >>> # ========== model inference ===========
        >>> # construct the model input dataset
        >>> datasetIn = vacl.ModelDataset(data)
        >>> # get the model output dataset
        >>> datasetOut = stream.requestOutputDataset()
        >>> # run model inference
        >>> stream.runStreamAsync(datasetIn, datasetOut)
        >>> # ========== model callback ===========
        >>> # parse model output dataset
        >>> def callback(op: vace.Op, inputDataset: vacl.ModelDataset, outputDataset: vacl.ModelDataset, status: vacl.CallBackStatus, userCtx: Any):
        >>>     results = outputDataset.getData()
        >>> datasetIn.destroy()
        >>> datasetOut.destroy()
    """

    # __DATASET_RECORD = []

    def __init__(self,
                 data: Union[np.ndarray, List[np.ndarray], Dataset],
                 type: MODEL_DATASET_TYPE = MODEL_DATASET_TYPE.INPUT):
        self._data = data
        self._ptr = None
        if isinstance(data, Dataset):
            self._ptr = data.ptr
            super().__init__(data.mode, data.detach, data.ptr)
        elif isinstance(data, np.ndarray):
            self._data = [data]
        self._type = type
        self._create()

    @property
    def type(self) -> str:
        """The Type of the model dataset."""
        return self._type

    def _create(self) -> None:
        """Create the dataset on the device."""
        if self._ptr is None:
            super().__init__(DATASET_MODE.BUFFER, True)
            for data in self._data:
                assert isinstance(data, np.ndarray)
                # 从numpy构建dataHandle
                hostHandle = getHandleFromNumpy(data)
                deviceHandle = hostHandle.to(DEVICE_TYPE.VACC)
                # 构建dataBuffer
                dataBuffer = DataBuffer(deviceHandle)
                self.addData(dataBuffer)

    def getFloatArray(self) -> List[List[float]]:
        """Parse the dataset from device.

        Args:
            index(int): The index of data buffer in dataset object.
        
        Returns:
            List[List[float]]: The float array of the data.
        """
        datas = []
        if self.type == MODEL_DATASET_TYPE.OUTPUT:
            for i in range(self.size):
                # 输出内存拷贝到host
                deviceBuffer = self.getData(i)
                deviceHandle = deviceBuffer.handle
                hostHandle = deviceHandle.to(DEVICE_TYPE.CPU)
                # 16位转32位
                floatArray = getFloatArrayFromHandle(hostHandle)
                datas.append(floatArray)
                hostHandle.destroy()
        elif self.type == MODEL_DATASET_TYPE.INPUT:
            for i in range(self.size):
                # 输出内存拷贝到host
                deviceBuffer = self.getData(i)
                deviceHandle = deviceBuffer.handle
                hostHandle = deviceHandle.to(DEVICE_TYPE.CPU)
                # 输入类型的数据直接转换回一维的数组
                data = getNumpyFromHandle(hostHandle, dtype=np.float).tolist()
                datas.append(data)
        else:
            raise RuntimeError(f"The type is unsupported: {self.type}.")
        return datas