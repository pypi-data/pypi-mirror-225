{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Step-by-step guide\n",
    "\n",
    "This guide shows step by step how a compartmental model is built and how its\n",
    "parameter can by inferred.\n",
    "\n",
    "First some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jaxopt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import diffrax\n",
    "import jaxopt\n",
    "import optax\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import pytensor.tensor as pt\n",
    "import scipy.optimize\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import icomo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Let us first define a system of ordinary differential equations (ODEs). As an example, we will make an SEIR model with an Erlang distributed latent period."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ODEs should always be defined with t, y and args, t is the time variable, y the\n",
    "# variables proper and args the other arguments\n",
    "def Erlang_SEIR(t, y, args):\n",
    "\n",
    "    # args can be time dependent or not, if there are time-dependent variable, args\n",
    "    # is passed as a tuple, where the first entry beta_t is a function that can be\n",
    "    # evaluated at t\n",
    "    beta_t, const_arg = args\n",
    "\n",
    "    # y and the other constant args are passed as dictionary in this example to facilite\n",
    "    # keeping track of the meaning of the variables\n",
    "    N = const_arg[\"N\"]\n",
    "    dy = {} # Create the return dictionary of the derivatives, it will have the same\n",
    "            # structure as y\n",
    "\n",
    "    # The derivative of the S compartment is -beta(t) * I * S / N\n",
    "    dy[\"S\"] = -beta_t(t) * y[\"I\"] * y[\"S\"] / N\n",
    "\n",
    "    # Latent period, use an helper function\n",
    "    dEs, outflow = icomo.erlang_kernel(\n",
    "        inflow=beta_t(t) * y[\"I\"] * y[\"S\"] / N,\n",
    "        Vars=y[\"Es\"], # y[\"Es\"] is assumed to be a list of compartments/variables to be\n",
    "                      # able to model the kernel\n",
    "        rate=const_arg[\"rate_latent\"],\n",
    "    )\n",
    "    dy[\"Es\"] = dEs\n",
    "\n",
    "    dy[\"I\"] = outflow - const_arg[\"rate_infectious\"] * y[\"I\"]\n",
    "\n",
    "    dy[\"R\"] = const_arg[\"rate_infectious\"] * y[\"I\"]\n",
    "\n",
    "    return dy # return the derivatives"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The above function defined the following set of equations:\n",
    "$$ \\begin{align}\n",
    "\\frac{\\mathrm dS(t)}{\\mathrm dt} &= -\\tfrac{1}{N}{\\beta(t)}SI,\\\\\n",
    "\\frac{\\mathrm dE^{(1)}(t)}{\\mathrm dt} &= \\tfrac{1}{N}\\beta(t) SI-\\mathrm{rate_latent} \\cdot n \\cdot E^{(1)},\\\\\n",
    "\\frac{\\mathrm dE^{(2)}(t)}{\\mathrm dt} &= \\mathrm{rate_latent} \\cdot n \\cdot E^{(1)} -\\mathrm{rate_latent} \\cdot n \\cdot E^{(2)},\\\\\n",
    "\\frac{\\mathrm dE^{(3)}(t)}{\\mathrm dt} &= \\mathrm{rate_latent} \\cdot n \\cdot E^{(2)} -\\mathrm{rate_latent} \\cdot n \\cdot E^{(3)},\\\\\n",
    "\\frac{\\mathrm dI(t)}{\\mathrm dt} &= \\mathrm{rate_latent} \\cdot n \\cdot E^{(3)} -\\mathrm{rate_infectious} \\cdot  I,\\\\\n",
    "\\frac{\\mathrm dR(t)}{\\mathrm dt} &=\\mathrm{rate_infectious} \\cdot  I,,\n",
    "\\end{align} $$\n",
    "Here $n = 3$ is the number of exposed compartments $E$. In the function above the exposed compartments are saved as list in `y[\"Es\"]`.\n",
    "The three equations $\\frac{\\mathrm dE^{(1 \\dots 3)}(t)}{\\mathrm dt}$ are defined in the [icomo.erlang_kernel](api/references.rst#icomo.erlang_kernel) function for convenience. This function also sets dynamically $n$ to the length of the list `y[\"Es\"]`.\n",
    "\n",
    "## Integrating ODEs\n",
    "\n",
    "Given some starting conditions and parameters we can integrate our system of ODEs:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len_sim = 365 # days\n",
    "num_points = len_sim\n",
    "\n",
    "### First set the time variables\n",
    "t_out = np.linspace(0, len_sim, num_points) # timepoints of the output\n",
    "t_solve_ODE = np.linspace(0, len_sim, num_points//2) # timepoints at which the ODE\n",
    "                                                     # is solved\n",
    "t_beta = np.linspace(0, len_sim, num_points//14) # timepoints at which the time-dependent\n",
    "                                             # variable is defined (every 2 weeks)\n",
    "\n",
    "### Define parameters\n",
    "N = 1e5 # population\n",
    "R0 = 1.5\n",
    "duration_latent = 3 # the average in days\n",
    "duration_infectious = 7 # the average in days\n",
    "beta0 = R0/duration_infectious # infection rate\n",
    "\n",
    "\n",
    "### Set parameters  for ODE\n",
    "arg_t = beta0 * np.ones(len(t_beta)) # beta might be time-depedent, but assume\n",
    "                                     # constant beta for now\n",
    "const_args = {\n",
    "    \"N\": N,\n",
    "    \"rate_latent\": 1/duration_latent,\n",
    "    \"rate_infectious\": 1/duration_infectious,\n",
    "}\n",
    "\n",
    "### Define starting conditions\n",
    "y0 = {\"Es\": [100, 100, 100], # multiple compartmentes for Erlang kernel\n",
    "      \"I\": 300,\n",
    "      \"R\": 0,\n",
    "    }\n",
    "# Susceptible compartment is N - other compartments\n",
    "y0[\"S\"] = N - jax.tree_util.tree_reduce(lambda x, y: x + y, y0)\n",
    "# This is equivalent to writing\n",
    "y0[\"S\"] = N - y0[\"R\"] - np.sum(y0[\"Es\"])\n",
    "\n",
    "\n",
    "# First parameters of the integrators have to be set\n",
    "integrator_object = icomo.ODEIntegrator(\n",
    "    ts_out=t_out,\n",
    "    t_0=min(t_solve_ODE),\n",
    "    ts_solver=t_solve_ODE,\n",
    "    ts_arg = t_beta,\n",
    ")\n",
    "\n",
    "# Then we can obtain a function that solves our system of ODEs\n",
    "SEIR_integrator = integrator_object.get_func(Erlang_SEIR)\n",
    "\n",
    "# And solve the ODE for our starting conditions and parameters\n",
    "output = SEIR_integrator(y0=y0, arg_t=arg_t, constant_args=const_args)\n",
    "\n",
    "f = plt.figure(figsize=(4,3))\n",
    "plt.plot(output[\"I\"])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Infectious compartment $I$\");"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We here use an ODE integrator built with the [icomo.ODEIntegrator](api/references.rst#icomo.ODEIntegrator) which wraps the ODE  solver from [Diffrax](https://docs.kidger.site/diffrax/). In general, the `constant_args` and variables `y0` passed to the integrator and subsequently\n",
    "to the ODE function can be a any nested list, tuple and/or dict, which is also called [pytree](https://jax.readthedocs.io/en/latest/pytrees.html). The output will have the same structure as `y0` except that its variables will received a prependet time dimension.\n",
    "`arg_t` has to be an ndimensional array, where the first dimension matches the length of `ts_arg`.\n",
    "\n",
    "## Simplify the construction of ODEs with `icomo.CompModel`\n",
    "The system of ODEs can by vastly simplified. Notice how the population subtracted from one compartment is always added exactly to another compartment.\n",
    "Furthermore, the substracted amount is always proportional to the population currently in the compartment. Making use of these two properties, one can specify such a system by a number of flows starting and ending in different compartments and parametrized by rates which are multiplied by the starting\n",
    "compartment. Such a spefication is possible with the class [icomo.CompModel](api/references.rst#icomo.CompModel):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def Erlang_SEIR_v2(t, y, args):\n",
    "    beta_t, const_arg = args\n",
    "\n",
    "    comp_model = icomo.CompModel(y)\n",
    "\n",
    "    comp_model.flow(start_comp=\"S\",\n",
    "                    end_comp=\"Es\",\n",
    "                    rate=y[\"I\"]/const_arg[\"N\"] * beta_t(t),\n",
    "                    label=\"beta(t) * I/N\", # label of the graph edge\n",
    "                    end_comp_is_list = True) # One has to specify that \"Es\" refers to\n",
    "                                             # a list of compartments\n",
    "    comp_model.erlang_flow(\"Es\", \"I\", const_arg[\"rate_latent\"],\n",
    "                           label=\"rate_latent (erlang)\")\n",
    "    comp_model.flow(\"I\", \"R\", const_arg[\"rate_infectious\"], label = \"rate_infectious\")\n",
    "    comp_model.view_graph()\n",
    "    return comp_model.dy\n",
    "\n",
    "# Check whether the resulting dynamics are the same as the previous version\n",
    "SEIR_integrator_v2 = integrator_object.get_func(Erlang_SEIR_v2)\n",
    "output2= SEIR_integrator_v2(y0=y0, arg_t=arg_t, constant_args=const_args)\n",
    "\n",
    "f = plt.figure(figsize=(4,3))\n",
    "plt.plot(output2[\"I\"])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Infectious compartment $I$\");"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Another advantage is the a `CompModel` object can display the graph with the `view_graph()` method, which helps the verify the parametrisation was correct.\n",
    "Specify in this case the `label` keyword when adding flows, these are displayed on the edges of the graph.\n",
    "\n",
    "Take notice that CompModel assumes that the variables/compartments `y` are saved in a dictionary and that for flow that follow and Erlang kernels, the corresponding compartments are in a list saved under the key of `start_comp.\n",
    "\n",
    "## Fitting/optimizing the model using Data\n",
    "\n",
    "We might to optimize some parameters of the model. This is readily achieved as it can be easily differenciated using [jax.grad](https://jax.readthedocs.io/en/latest/notebooks/quickstart.html#taking-derivatives-with-grad).\n",
    "\n",
    "Concretely, we will optimize the `beta_t` variable. We defined it every 14 days. The\n",
    "[icomo.ODEIntegrator](api/references.rst#icomo.ODEIntegrator) class uses a cubic\n",
    "interpolation to obtain a continuous approximation inbetween. For completeness, we\n",
    "will also need to optimize the initial number of infected `I0`.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data are the number of COVID-19 cases in England during 2022\n",
    "data = [236576, 188567, 118275, 181068, 229901, 275647, 222174, 172980, 120287, 93615, 95790, 132959, 115245, 103219, 96412, 86325, 77950, 98097, 131514, 118857, 111760, 100324, 91730, 81733, 102365, 127364, 113201, 108668, 96200, 84026, 73512, 87702, 105051, 93949, 88418, 76644, 63264, 52305, 60552, 76483, 69661, 64339, 52293, 44559, 37529, 41755, 54745, 52502, 51572, 44716, 33241, 34647, 37720, 45131, 39188, 36476, 30631, 27837, 25089, 31360, 44649, 44795, 46179, 43761, 41408, 38759, 49026, 68520, 70111, 73531, 70510, 67030, 62078, 75738, 99832, 93708, 91752, 82853, 75285, 67417, 81054, 109286, 99095, 94185, 82905, 72430, 61456, 68336, 92857, 80126, 73643, 54791, 47462, 37592, 42179, 53727, 49101, 44750, 38709, 32988, 27885, 30952, 37371, 33771, 31685, 26638, 21615, 19924, 20144, 25223, 25772, 21457, 18464, 15703, 13210, 14715, 17108, 14560, 13055, 11608, 10012, 8354, 9034, 11907, 13318, 11672, 10221, 8954, 7517, 9062, 10702, 9748, 8725, 7642, 6942, 6120, 7973, 9417, 8286, 7638, 6820, 5821, 5019, 5997, 7313, 6679, 6293, 5753, 5409, 4988, 5680, 7115, 7093, 7011, 6209, 6635, 7492, 9815, 11747, 11411, 11784, 11319, 10784, 10077, 12693, 15272, 15141, 14837, 14225, 13919, 13623, 16997, 19942, 20896, 20873, 19590, 18349, 16800, 20778, 25104, 25041, 24601, 24240, 23650, 21961, 27780, 33704, 31415, 29698, 26454, 24611, 21246, 25096, 29826, 26946, 23856, 21100, 18359, 15017, 17236, 18718, 16670, 16169, 14158, 12378, 9934, 11275, 13299, 11725, 10544, 9329, 8508, 7325, 8426, 9835, 9170, 8353, 7296, 6548, 5420, 6547, 8068, 7309, 6748, 6193, 5339, 4495, 5363, 6424, 5559, 5032, 4564, 4012, 3502, 4085, 5224, 4778, 4554, 3796, 3451, 3112, 3439, 4662, 5226, 4615, 4350, 3808, 3417, 4288, 5125, 4578, 4235, 3747, 3553, 3268, 4347, 5307, 5147, 4973, 4634, 4134, 3521, 4339, 6166, 7828, 7553, 6815, 6485, 5719, 7240, 8617, 8251, 8414, 7895, 7615, 7065, 9204, 11692, 10965, 10231, 9389, 8950, 7053, 8558, 10497, 9461, 8768, 8134, 7970, 6442, 7780, 10002, 8233, 7598, 6576, 6297, 4968, 5523, 6807, 5665, 5449, 4855, 4401, 3583, 4271, 5130, 4549, 4014, 3678, 3107, 2665, 3267, 4321, 3829, 3576, 3205, 2893, 2433, 2912, 3923, 3534, 3260, 3037, 2773, 2430, 2890, 3937, 3805, 3616, 3329, 2902, 2551, 3448, 4639, 4386, 3980, 3505, 3596, 2748, 3786, 5325, 5241, 5195, 4537, 4216, 3570, 4631, 6986, 7111, 6533, 6094, 6084, 4743, 5772, 9073, 8631, 7802, 6877, 5741, 4132, 3694, 4950, 6605, 8419, 7718]\n",
    "data = np.array(data)\n",
    "N_England = 50e6\n",
    "\n",
    "\n",
    "# Setup a function that simulate the spread given a time-dependent beta_t and the initial\n",
    "# infected I0\n",
    "def simulation(args_optimization):\n",
    "    beta_t = args_optimization['beta_t']\n",
    "\n",
    "    # Spread out the infected over the exposed and infectious compartments\n",
    "    I0 = args_optimization['I0']/2\n",
    "    Es_0 = [args_optimization['I0']/6 for _ in range(3)]\n",
    "\n",
    "    # Update const_args\n",
    "    const_args['N']=N_England\n",
    "\n",
    "    # Update starting conditions\n",
    "    y0 = {\"Es\": Es_0,\n",
    "          \"I\": I0,\n",
    "          \"R\": 0,\n",
    "        }\n",
    "    y0[\"S\"] = N_England - jax.tree_util.tree_reduce(lambda x, y: x + y, y0)\n",
    "\n",
    "    # Reuse the integrator define above, arg_t is now time-dependent\n",
    "    output = SEIR_integrator(y0=y0, arg_t=beta_t, constant_args=const_args)\n",
    "\n",
    "    # beta_t is only defined every 14 days, for plotting we will need\n",
    "    # also the interpolated values.\n",
    "    beta_t_interpolated = icomo.interpolation_func(t_beta, beta_t, 'cubic').evaluate(t_out)\n",
    "    # The integrator uses internally the same interpolation function\n",
    "    output[\"beta_t_interpolated\"] = beta_t_interpolated\n",
    "\n",
    "    return output\n",
    "\n",
    "# Define our loss function\n",
    "@jax.jit\n",
    "def loss(args_optimization):\n",
    "    output = simulation(args_optimization)\n",
    "    new_infected = -jnp.diff(output[\"S\"]) # The difference in the susceptible population\n",
    "                                          # are the newly infected\n",
    "\n",
    "    # Use the mean squared difference as our loss, weighted by the number of new infected\n",
    "    loss = jnp.mean((new_infected-data[1:])**2/(new_infected+1))\n",
    "    # Notice the use of jax.numpy instead of number for the calculation. This is\n",
    "    # necessary. as it allows the auto-differentiation of our loss function.\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Define initial parameters, convert them to np.array in order to avoid recompilations\n",
    "init_params = {'beta_t': beta0 * np.ones_like(t_beta), \"I0\":np.array(float(data[0]*duration_infectious))}\n",
    "\n",
    "start_time = time.time()\n",
    "# Differenciate our loss\n",
    "value_and_grad_loss = jax.jit(jax.value_and_grad(loss))\n",
    "value_and_grad_loss(init_params)\n",
    "print(f\"Compilation duration: {(time.time()-start_time):.1f}s\")\n",
    "\n",
    "### Solve our minimization problem\n",
    "solver = jaxopt.ScipyMinimize(fun=value_and_grad_loss, value_and_grad=True, method=\"L-BFGS-B\", jit=False)\n",
    "\n",
    "start_time = time.time()\n",
    "res = solver.run(init_params)\n",
    "end_time = time.time()\n",
    "print(f\"Minimization duration: {(end_time-start_time):.3f}s\")\n",
    "\n",
    "print(f\"Number of function evaluations: {res.state.iter_num}\\n\"\n",
    "      f\"Final cost: {res.state.fun_val:.3f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We decided here to use [jaxopt.ScipyMinimize](https://jaxopt.github.io/stable/_autosummary/jaxopt.ScipyMinimize.html) as minimization function, which wraps the [scipy.minimize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize) function. The advantage to scipy.minimize is that we can use pytrees as optimization variables instead flat arrays. Otherwise scipy.minimize works equally\n",
    "well.\n",
    "\n",
    "In order to speed up the fitting procedure, we compile our loss function using [jax.jit](https://jax.readthedocs.io/en/latest/notebooks/quickstart.html#using-jit-to-speed-up-functions),\n",
    "a just-in-time (jit) compiler. This improves the runtime of the minimization by about a factor 20.\n",
    "\n",
    "Notice the use of jax.numpy inside the loss function but not outside. It is a good habit\n",
    "to only use jax.numpy for calculations that needs to be automatically differentiated and\n",
    "otherwise the usual numpy. It might avoid the unnecessary tracing/graph-building of such\n",
    "variables and can also lead to errors if function still depend on traced variables outside\n",
    "the current scope.\n",
    "\n",
    "Let us check the results:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 1,figsize=(4,5), height_ratios=(1,2.5))\n",
    "plt.sca(axes[0])\n",
    "plt.plot(t_out[:], simulation(res.params)[\"beta_t_interpolated\"]*duration_infectious, color=\"tab:blue\", label=\"model\", lw=2)\n",
    "plt.ylabel(\"Reproduction\\nnumber R_t\")\n",
    "plt.xlim(t_out[0], t_out[-1])\n",
    "plt.axhline([1], color=\"lightgray\", ls = \"--\")\n",
    "plt.sca(axes[1])\n",
    "plt.plot(t_out, data, color=\"gray\", ls=\"\", marker=\"d\", ms=3, label=\"data\")\n",
    "plt.plot(t_out[1:], -np.diff(simulation(res.params)[\"S\"]), color=\"tab:blue\", label=\"model\", lw=2)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Cases\");\n",
    "plt.legend();\n",
    "plt.xlim(t_out[0], t_out[-1]);\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fitting using Adam\n",
    "\n",
    "For high-dimensional optimization systems that are significantly underdetermined it\n",
    "might be advantageous to use a gradient descent algorithm instead of L-BFGS. This is not\n",
    "the case for this system, but we show it here as an example using [optax](https://optax.readthedocs.io/en/latest/):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_learning_rate = 5e-2\n",
    "schedule = optax.exponential_decay(init_value=start_learning_rate,\n",
    "                                   transition_steps=1000,\n",
    "                                   decay_rate=1/2,\n",
    "                                   transition_begin=50,\n",
    "                                   staircase=False,\n",
    "                                   end_value=None)\n",
    "optimizer = optax.adam(learning_rate=schedule)\n",
    "# Initialize parameters of the model + optimizer.\n",
    "opt_state = optimizer.init(init_params)\n",
    "losses = []\n",
    "params_adam=init_params\n",
    "for i in (pbar := tqdm(range(2000))):\n",
    "    func_val, grads = value_and_grad_loss(params_adam)\n",
    "    if i%10 == 0:\n",
    "        pbar.set_description(f\"Loss {func_val:.5f}\")\n",
    "    losses.append(func_val)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params_adam = optax.apply_updates(params_adam, updates)\n",
    "\n",
    "f = plt.figure(figsize=(3,2))\n",
    "plt.plot(losses)\n",
    "plt.ylim(1e3,1e4)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\");"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We obtain similar results:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 1,figsize=(4,5), height_ratios=(1,2.5))\n",
    "plt.sca(axes[0])\n",
    "plt.plot(t_out[:], simulation(params_adam)[\"beta_t_interpolated\"]*duration_infectious, color=\"tab:blue\", label=\"model\", lw=2)\n",
    "plt.ylabel(\"Reproduction\\nnumber R_t\")\n",
    "plt.xlim(t_out[0], t_out[-1])\n",
    "plt.axhline([1], color=\"lightgray\", ls = \"--\")\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plt.plot(t_out, data, color=\"gray\", ls=\"\", marker=\"d\", ms=3, label=\"data\")\n",
    "plt.plot(t_out[1:], -np.diff(simulation(params_adam)[\"S\"]), color=\"tab:blue\", label=\"model\", lw=2)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Cases\");\n",
    "plt.legend();\n",
    "plt.xlim(t_out[0], t_out[-1]);\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bayesian analysis\n",
    "\n",
    "With fitting procedure one doesn't obtain good error estimates of the fitted parameters.\n",
    "As such, a Bayesian model helps to estimate the credible interval of the parameters\n",
    "of interest. Let us make such a model for our system of equations.\n",
    "\n",
    "The central part is the modelling of the infection rate beta_t. In a bayesian\n",
    "spirit, we assume that differences between subsequent knots of the spline interpolation\n",
    "follow an hierarchical model: We assume that the deviation of the size of changes in\n",
    "infectiousness is similar across the changes. The equations for the\n",
    "beta_t are therefore:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sigma_\\beta &\\sim HalfCauchy\\left(0.2\\right),\\\\\n",
    "\\Delta \\beta_i &\\sim \\mathcal{N\\left(0, \\sigma_\\beta\\right)}, \\\\\n",
    "\\beta_k &= \\beta_0 \\cdot \\exp \\left(\\sum_i^{k} \\Delta \\beta_i\\right),\n",
    "\\end{align}\n",
    "$$\n",
    "where $\\beta_k$ defines the k-th spline of the cubic interpolation. Let us define the\n",
    "model:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reduce the length of the simulation for runtime reasons\n",
    "t_out_bayes = np.arange(100)\n",
    "data_bayes = data[t_out_bayes]\n",
    "t_solve_ODE_bayes = np.linspace(t_out_bayes[0], t_out_bayes[-1], len(t_out_bayes)//2)\n",
    "t_beta_bayes = np.linspace(t_out_bayes[0], t_out_bayes[-1], len(t_out_bayes)//14)\n",
    "\n",
    "# We therefore need a new ODEIntegrator object\n",
    "integrator_object_bayes = icomo.ODEIntegrator(\n",
    "    ts_out=t_out_bayes,\n",
    "    ts_solver=t_solve_ODE_bayes,\n",
    "    ts_arg = t_beta_bayes,\n",
    ")\n",
    "\n",
    "with pm.Model(coords={\"time\": t_out_bayes, \"t_beta\": t_beta_bayes}) as model:\n",
    "\n",
    "    # We also allow the other rates of the compartments to vary\n",
    "    duration_latent_var = pm.LogNormal(\"duration_latent\", mu=np.log(duration_latent),\n",
    "                                                           sigma=0.1)\n",
    "    duration_infectious_var = pm.LogNormal(\"duration_infectious\",\n",
    "                                           mu=np.log(duration_infectious),\n",
    "                                           sigma=0.3)\n",
    "\n",
    "    # Construct beta_t\n",
    "    R0 = pm.LogNormal(\"R0\", np.log(1), 1)\n",
    "    beta_0_var = 1 * R0/duration_infectious_var\n",
    "    beta_t_var =beta_0_var*pt.exp(pt.cumsum(icomo.hierarchical_priors(\"beta_t_log_diff\",\n",
    "                                                                      dims=(\"t_beta\",))))\n",
    "\n",
    "    # Set the other parameters and initial conditions\n",
    "    const_args_var = {\n",
    "        \"N\": N_England,\n",
    "        \"rate_latent\": 1/duration_latent_var,\n",
    "        \"rate_infectious\": 1/duration_infectious_var,\n",
    "    }\n",
    "    infections_0_var = pm.LogNormal(\"infections_0\", mu=np.log(data_bayes[0]*duration_infectious),\n",
    "                                                    sigma=2)\n",
    "\n",
    "    y0_var = {\"Es\": [infections_0_var/6 for _ in range(3)],\n",
    "      \"I\": infections_0_var/2,\n",
    "      \"R\": 0}\n",
    "    y0_var[\"S\"] = N_England - jax.tree_util.tree_reduce(lambda x, y: x + y, y0_var)\n",
    "\n",
    "    # Define our integrator, notice that we use get_op instead of get_func. get_op returns\n",
    "    # a pytensor operation that we can use in a pymc object. Such an operation isn't\n",
    "    # allowed to return a pytree, therefore we have to define which of the dict entries\n",
    "    # we want to have returned.\n",
    "    # We do keep the same ODE function\n",
    "    SEIR_integrator_op = integrator_object_bayes.get_op(Erlang_SEIR,\n",
    "                                                  return_shapes=[() for _ in range(2)],\n",
    "                                                  list_keys_to_return=[\"S\", \"I\"])\n",
    "\n",
    "    # And solve the ODE for our starting conditions and parameters\n",
    "    S, I = SEIR_integrator_op(y0=y0_var, arg_t=beta_t_var, constant_args=const_args_var)\n",
    "    pm.Deterministic(\"I\", I)\n",
    "    new_cases = -pt.diff(S)\n",
    "    pm.Deterministic(\"new_cases\", new_cases)\n",
    "\n",
    "    # And define our likelihood\n",
    "    sigma_error = pm.HalfCauchy(\"sigma_error\", beta=1)\n",
    "    pm.StudentT(\"cases_observed\", nu=4, mu=new_cases, sigma = sigma_error * pt.sqrt(new_cases+1),\n",
    "               observed = data_bayes[1:])\n",
    "\n",
    "    # Like before,w we also want to save the interpolated beta_t\n",
    "    beta_t_interp = icomo.interpolate_pytensor(t_beta_bayes, t_out_bayes, beta_t_var)\n",
    "    pm.Deterministic(\"beta_t_interp\", beta_t_interp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And then sample from it. We use the numpyro sampler, as it uses JAX which\n",
    "is more efficient as our differencial equation solver is written using jax.\n",
    "The normal pymc sampler also works. It would convert all the model in C,\n",
    "except our ODE solver, which would still run using JAX."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trace = pm.sample(\n",
    "    model=model,\n",
    "    tune=300,\n",
    "    draws=200,\n",
    "    cores=4,\n",
    "    nuts_sampler=\"numpyro\",\n",
    "    target_accept=0.9,\n",
    ")\n",
    "warnings = pm.stats.convergence.run_convergence_checks(trace,model=model,)\n",
    "pm.stats.convergence.log_warnings(warnings)\n",
    "print(f\"Maximal R-hat value: {max(az.rhat(trace).max().values()):.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice how much longer the sampling takes compared to the simple fitting of the dynamics.\n",
    "It is also recommended to let it run for longer, to make sure the estimated posterior\n",
    "distribution converged. Let us plot the inferred parameters:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 1,figsize=(4,5), height_ratios=(1,2.5))\n",
    "plt.sca(axes[0])\n",
    "beta_t_post = trace.posterior[\"beta_t_interp\"].to_numpy().reshape((-1, len(t_out_bayes)))\n",
    "R_t_post = beta_t_post * trace.posterior[\"duration_infectious\"].to_numpy().flatten()[:, None]\n",
    "plt.plot(t_out_bayes, np.median(R_t_post, axis=0), color=\"tab:blue\", alpha = 0.3)\n",
    "plt.fill_between(t_out_bayes, *np.percentile(R_t_post, q=(2.5,97.5), axis=0), color=\"tab:blue\", alpha = 0.3)\n",
    "plt.ylabel(\"Reproduction\\nnumber R_t\")\n",
    "plt.xlim(t_out_bayes[0], t_out_bayes[-1])\n",
    "plt.axhline([1], color=\"lightgray\", ls = \"--\")\n",
    "\n",
    "plt.sca(axes[1])\n",
    "new_cases_post = trace.posterior[\"new_cases\"].to_numpy().reshape((-1, len(t_out_bayes)-1))\n",
    "plt.plot(t_out_bayes[1:], np.median(new_cases_post, axis=0), color=\"tab:blue\", alpha = 0.3)\n",
    "plt.fill_between(t_out_bayes[1:], *np.percentile(new_cases_post, q=(2.5,97.5), axis=0),\n",
    "                 color=\"tab:blue\", alpha = 0.3, label=\"Model (95% CI)\")\n",
    "plt.plot(t_out_bayes, data_bayes, marker=\"d\", color=\"black\", ls=\"\", ms=3, label=\"Data\");\n",
    "plt.ylabel(\"Cases\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.xlim(t_out_bayes[0], t_out_bayes[-1]);\n",
    "plt.legend();\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1,2, figsize=(5,2.2))\n",
    "x = np.linspace(1,4, 100)\n",
    "plt.sca(axes[0])\n",
    "plt.hist(trace.posterior['duration_latent'].data.flatten(), bins=30, density=True, label=\"Posterior\", alpha=0.5)\n",
    "plt.plot(x, np.exp(pm.logp(pm.LogNormal.dist(np.log(duration_latent), 0.1), x).eval()), color=\"gray\", label=\"Prior\")\n",
    "plt.xlim(2, 4.5)\n",
    "plt.xlabel(\"Duration latent\\nperiod\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.sca(axes[1])\n",
    "x = np.linspace(3,19, 100)\n",
    "plt.hist(trace.posterior['duration_infectious'].data.flatten(), bins=30, density=True, label=\"Posterior\", alpha=0.5)\n",
    "plt.plot(x, np.exp(pm.logp(pm.LogNormal.dist(np.log(duration_infectious), 0.3), x).eval()), color=\"gray\", label=\"Prior\")\n",
    "plt.xlim(3,19)\n",
    "plt.xlabel(\"Duration infectious\\nperiod\")\n",
    "plt.legend()\n",
    "plt.tight_layout();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal R-hat value: 1.021\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_env",
   "language": "python",
   "name": "dev_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}