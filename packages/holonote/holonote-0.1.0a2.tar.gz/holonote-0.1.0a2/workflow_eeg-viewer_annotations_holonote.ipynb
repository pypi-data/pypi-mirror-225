{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Viewer\n",
    "![status](https://img.shields.io/badge/status-in%20progress-orange)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/holoviz-topics/neuro/main/workflows/eeg-viewer/assets/230524_eeg-viewer.png\" alt=\"eeg viewer preview\" width=\"450\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This workflow is intended to demonstrate the visualization of a set of 1D EEG timeseries with HoloViz and Bokeh tools.\n",
    "\n",
    "For details specific to this workflow, such as goals, specifications, and bottlenecks, please see this workflow's [readme](./readme_eeg-viewer.md).\n",
    "\n",
    "For a summary of EEG research, data, and software, please see [neuro/wiki/EEG-notes](https://github.com/holoviz-topics/neuro/wiki/EEG-notes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Requirements</p>\n",
    "    <p>This workflow notebook requires the <a href=\"./environment.yml\">environment</a> specified in this workflow directory.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import colorcet as cc\n",
    "import holoviews as hv\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "from bokeh.models import HoverTool, WheelZoomTool\n",
    "from holoviews import Dataset\n",
    "from holoviews.operation.datashader import rasterize\n",
    "from holoviews.plotting.links import RangeToolLink\n",
    "from hvneuro import download_file\n",
    "from neurodatagen.eeg import generate_eeg_powerlaw\n",
    "from scipy.stats import zscore\n",
    "\n",
    "hv.extension(\"bokeh\")\n",
    "pn.extension(template=\"material\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intake data\n",
    "Downloading the data if it does not already exists. The data size is 2.6 MB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"https://physionet.org/files/eegmmidb/1.0.0/S001/S001R04.edf?download\"\n",
    "local_data_path = \"../../data/\"\n",
    "local_file_path = download_file(url, local_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and show the info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_edf(local_file_path, preload=True)\n",
    "raw.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the channel names, types, signal ranges, and uncompressed size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather the annotations\n",
    "Getting the annotation data and clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get annotations into a Pandas DataFrame\n",
    "annotations = raw.annotations.to_data_frame()\n",
    "annotations[\"start_time\"] = annotations[\"onset\"]\n",
    "duration_seconds = pd.to_timedelta(annotations[\"duration\"], \"s\")\n",
    "annotations[\"end_time\"] = annotations[\"start_time\"] + duration_seconds\n",
    "annotations = annotations.drop([\"onset\", \"duration\"], axis=1)\n",
    "\n",
    "# For now we convert it too seconds since orig_time\n",
    "orig_time = raw.annotations.orig_time.replace(tzinfo=None)\n",
    "annotations[\"start_time\"] = (annotations[\"start_time\"] - orig_time).dt.total_seconds()\n",
    "annotations[\"end_time\"] = (annotations[\"end_time\"] - orig_time).dt.total_seconds()\n",
    "\n",
    "unique_descriptions = annotations[\"description\"].unique()\n",
    "color_map = dict(zip(unique_descriptions, cc.glasbey))\n",
    "\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from holonote.annotate import Annotator\n",
    "\n",
    "# Want to add more automatic way to set this up.\n",
    "# annotator = Annotator(spec={\"time\": np.datetime64}, fields=[\"description\"])\n",
    "annotator = Annotator(spec={\"time\": float}, fields=[\"description\"])\n",
    "\n",
    "if annotator.df.empty:\n",
    "    # Only run once!\n",
    "    for n in annotations.itertuples():\n",
    "        annotator.set_range(n.start_time, n.end_time)\n",
    "        annotator.add_annotation(description=n.description)\n",
    "    annotator.commit()\n",
    "\n",
    "\n",
    "# This does not work with annotations yet\n",
    "range_style = {\n",
    "    \"color\": hv.dim(\"description\").categorize(color_map),\n",
    "    \"show_legend\": False,\n",
    "}\n",
    "range_style = {\"show_legend\": False}\n",
    "\n",
    "# Using an empty Curve to makes it possible to reuse the overlay.\n",
    "annotations_overlay = annotator.overlay(hv.Curve([]), range_style=range_style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean channel names, set sensor positions, and reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean up the channel names\n",
    "raw.rename_channels(lambda s: s.strip(\".\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # preview available montages that are shipped with MNE\n",
    "# mne.channels.get_builtin_montages(descriptions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Let's use the standard 10-20\n",
    "# montage = mne.channels.make_standard_montage(\"standard_1020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # plot the assigned positions of our data channels\n",
    "# raw.set_montage(montage, match_case=False)\n",
    "# sphere=(0, 0.015, 0, 0.099) #manually adjust the y origin coord and radius a bit\n",
    "# raw.plot_sensors(show_names=True, sphere=sphere);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# re-reference EEG data to the average over all recording channels\n",
    "raw.set_eeg_reference(\"average\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather the data for plotting into simple arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time = raw.times\n",
    "channels = raw.ch_names\n",
    "\n",
    "# get the EEG data (for this data set, all channels are EEG anyways)\n",
    "eeg_indices = mne.pick_types(raw.info, eeg=True)\n",
    "data = raw.get_data(picks=eeg_indices, units={\"eeg\": \"uV\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize real data\n",
    "Plotting constants and tools for the next plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_ch_disp = 10  # max channels to initially display\n",
    "max_t_disp = 5  # max time in seconds to initially display\n",
    "\n",
    "spacing = 2.5  # Spacing between channels\n",
    "offset = np.std(data) * spacing\n",
    "\n",
    "y_positions = np.arange(len(channels)) * offset\n",
    "yticks = list(zip(y_positions, channels))\n",
    "\n",
    "clim_spacing = 1.2\n",
    "\n",
    "hover = HoverTool(\n",
    "    tooltips=[\n",
    "        (\"Channel\", \"@channel\"),\n",
    "        (\"Time\", \"$x s\"),\n",
    "        (\"Amplitude\", \"@original_amplitude ÂµV\"),\n",
    "    ]\n",
    ")\n",
    "wheel = WheelZoomTool(\n",
    "    zoom_together=\"none\",\n",
    "    dimensions=\"width\",\n",
    "    maintain_focus=False,\n",
    ")\n",
    "tools = [\"save\", \"pan\", wheel, \"box_zoom\", \"reset\", hover]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the EEG viewer and applying annotation to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create eeg_viewer\n",
    "data_with_offset = data + (np.arange(len(data))[:, np.newaxis] * offset)\n",
    "max_data = data_with_offset.max()\n",
    "ds = hv.Dataset(\n",
    "    (channels, time, data_with_offset.T, data.T),\n",
    "    kdims=[\"channel\", \"Time\"],\n",
    "    # vdims=[\"Amplitude\", \"original_amplitude\"],  # Original amplitude does not work great with HoverTool in an overlay plot.\n",
    "    vdims=[\"Amplitude\"],\n",
    ")\n",
    "eeg_viewer = (\n",
    "    ds.to(hv.Curve, groupby=\"channel\")\n",
    "    .overlay()\n",
    "    .opts(hv.opts.Curve(color=\"black\", line_width=1, tools=[hover, \"xwheel_zoom\"]))\n",
    ")\n",
    "\n",
    "# Combine with annotations\n",
    "eeg_with_annotations = annotations_overlay * eeg_viewer\n",
    "\n",
    "# Style the EEG Viewer\n",
    "eeg_with_annotations = eeg_with_annotations.opts(\n",
    "    padding=0,\n",
    "    xlabel=\"Time (s)\",\n",
    "    ylabel=\"Channel\",\n",
    "    yticks=yticks,\n",
    "    show_legend=False,\n",
    "    aspect=1.5,\n",
    "    responsive=True,\n",
    "    shared_axes=False,\n",
    "    backend_opts={\n",
    "        \"x_range.bounds\": (time.min(), time.max()),\n",
    "        \"y_range.bounds\": (data.min(), max_data),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the minimap, this is done by [rasterizing](https://holoviews.org/user_guide/Large_Data.html#holoviews-operations-for-datashading) it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute z-scores across time for each channel\n",
    "z_data = zscore(data, axis=1)\n",
    "\n",
    "# Generate the zscored image for the minimap using the y tiack positions from the eeg_viewer\n",
    "minimap = rasterize(\n",
    "    hv.Image((time, y_positions, z_data), [\"Time (s)\", \"Channel\"], \"Amplitude (uV)\")\n",
    ")\n",
    "\n",
    "# Style the minimap\n",
    "minimap = minimap.opts(\n",
    "    cmap=\"RdBu_r\",\n",
    "    colorbar=False,\n",
    "    xlabel=\"\",\n",
    "    alpha=0.5,\n",
    "    yticks=[yticks[0], yticks[-1]],\n",
    "    height=100,\n",
    "    responsive=True,\n",
    "    default_tools=[\"\"],\n",
    "    shared_axes=False,\n",
    "    clim=(-z_data.std() * clim_spacing, z_data.std() * clim_spacing),\n",
    "    xlim=(time.min(), time.max()),  # If annotations exceed the time of the plot\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create RangeToolLink between the minimap and the main EEG viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_y_disp = data_with_offset[max_ch_disp - 1].max()\n",
    "link = RangeToolLink(\n",
    "    minimap,\n",
    "    eeg_viewer,\n",
    "    axes=[\"x\", \"y\"],\n",
    "    boundsx=(None, max_t_disp),\n",
    "    boundsy=(None, max_y_disp),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the EEG Viewer with the minimap and making it a Panel app "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eeg_with_minimap = (eeg_with_annotations + minimap * annotations_overlay).cols(1)\n",
    "\n",
    "eeg_app = pn.panel(eeg_with_minimap, min_height=650).servable(\n",
    "    target=\"main\", title=\"EEG Viewer with HoloViz and Bokeh\"\n",
    ")\n",
    "eeg_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Select a range in the plot by clicking around, and add an annotation with the cell below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotator.add_annotation(description=\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Saving it to the database can be done with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotator.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
